{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232b3847",
   "metadata": {},
   "source": [
    "# Project 3: Perfect Vine Compilation\n",
    "## Group 7\n",
    "### Hayley Carney, Rohan Enagala, Stephen Jennings, Basil Mullings, Utkarsh Karki, Sandeep Sonawane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a137f9f",
   "metadata": {},
   "source": [
    "## Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119581d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Add in import statements as needed\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ca97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def display_video_thumbnails(df_or_ids, max_images=25, columns=5, title=\"Selected Videos\"):\n",
    "    \"\"\"\n",
    "    Retrieves and displays thumbnail images for a list of videos.\n",
    "\n",
    "    Args:\n",
    "        df_or_ids (pd.DataFrame or list/pd.Series): \n",
    "            Either a DataFrame containing 'video_id_short' or a list/Series \n",
    "            of 'video_id_short' strings.\n",
    "        max_images (int): The maximum number of images to display. Defaults to 25.\n",
    "        columns (int): The number of columns in the display grid. Defaults to 5.\n",
    "        title (str): The title for the plot. Defaults to \"Selected Videos\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Determine the list of short IDs ---\n",
    "    if isinstance(df_or_ids, pd.DataFrame):\n",
    "        if 'video_id_short' not in df_or_ids.columns:\n",
    "            print(\"‚ùå Error: DataFrame must contain the 'video_id_short' column.\")\n",
    "            return\n",
    "        # Use the IDs from the DataFrame (e.g., if you pass df_data[:10])\n",
    "        short_ids = df_or_ids['video_id_short'].tolist()\n",
    "        \n",
    "    elif isinstance(df_or_ids, (list, pd.Series)):\n",
    "        # Use the list or Series directly (e.g., if you pass short_ids_list)\n",
    "        short_ids = list(df_or_ids) \n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Error: Input must be a DataFrame, list, or pandas Series of IDs.\")\n",
    "        return\n",
    "\n",
    "    if not short_ids:\n",
    "        print(\"üì¶ Found 0 IDs to display.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    num_found = len(short_ids)\n",
    "    print(f\"üì¶ Found {num_found} IDs. Displaying first {min(num_found, max_images)}.\")\n",
    "    \n",
    "    # Limit the number of IDs to display\n",
    "    ids_to_display = short_ids[:max_images]\n",
    "    num_to_display = len(ids_to_display)\n",
    "    \n",
    "    # Calculate rows needed for the grid display\n",
    "    rows = (num_to_display + columns - 1) // columns\n",
    "    \n",
    "    # 2. Setup the plot grid\n",
    "    plt.figure(figsize=(columns * 3, rows * 3))\n",
    "    plt.suptitle(f\"Thumbnails for: {title}\", fontsize=16)\n",
    "    # print(\",\".join(short_ids)) # Optionally removed this large print\n",
    "\n",
    "    # 3. Iterate through IDs and display images\n",
    "    for i, video_id in enumerate(ids_to_display):\n",
    "        # Construct the full path\n",
    "        image_path = THUMBNAIL_BASE_DIR / f\"{video_id}.png\"\n",
    "        \n",
    "        plt.subplot(rows, columns, i + 1)\n",
    "        \n",
    "        # Determine the ID string to display in the title\n",
    "        displayed_id = video_id            \n",
    "        try:\n",
    "            # Load and display the image\n",
    "            img = Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "\n",
    "            # Use the possibly censored ID for the title\n",
    "            plt.title(f\"{displayed_id}\", fontsize=8) \n",
    "            plt.axis('off') # Hide axis ticks and labels\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            plt.title(\"Missing\", fontsize=8, color='red')\n",
    "            plt.text(0.5, 0.5, \"Image Not Found\", ha='center', va='center', color='red')\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd92d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(jsonl_path):\n",
    "    \"\"\"\n",
    "    Loads embeddings, filenames, and video_id_short from the JSONL file, \n",
    "    ensures consistent shape, and mean-pools any (16, D) time-series \n",
    "    embeddings to (D,).\n",
    "    \n",
    "    Returns: (DataFrame with 'filename', 'embedding', 'video_id_short', \n",
    "              list of numpy arrays)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    skipped_count = 0\n",
    "    expected_shape = None\n",
    "    print(f\"Loading data from {jsonl_path}...\")\n",
    "    \n",
    "    raw_data = []\n",
    "    try:\n",
    "        with open(jsonl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    item = json.loads(line)\n",
    "                    raw_data.append({\n",
    "                        'filename': item['filename'],\n",
    "                        # üîë FIX: Extract the video_id_short field\n",
    "                        'video_id_short': item.get('video_id_short', None),\n",
    "                        'whisper_transcript': item.get('whisper_transcript', None),\n",
    "                        'embedding': np.array(item['embedding'], dtype=np.float32)\n",
    "                    })\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error during file read: {e}\")\n",
    "        return pd.DataFrame(), []\n",
    "\n",
    "    if not raw_data:\n",
    "        print(\"No data found in the input file.\")\n",
    "        return pd.DataFrame(), []\n",
    "\n",
    "    for item in raw_data:\n",
    "        current_embedding = item['embedding']\n",
    "        # filename = item['filename'] # Not needed here, but kept in item\n",
    "        \n",
    "        if current_embedding.size == 0:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        if current_embedding.ndim == 2 and current_embedding.shape[0] == 16:\n",
    "            current_embedding = np.mean(current_embedding, axis=0)\n",
    "            item['embedding'] = current_embedding\n",
    "\n",
    "        if expected_shape is None:\n",
    "            expected_shape = current_embedding.shape\n",
    "            data.append(item)\n",
    "        elif current_embedding.shape == expected_shape:\n",
    "            data.append(item)\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "            \n",
    "    # Note: df now includes 'video_id_short'\n",
    "    df = pd.DataFrame(data)\n",
    "    embeddings = list(df['embedding'].values)\n",
    "\n",
    "    print(f\"Successfully loaded {len(embeddings)} consistent embeddings (Skipped {skipped_count} invalid/inconsistent entries).\")\n",
    "    return df, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a970db7",
   "metadata": {},
   "source": [
    "## Data Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6395f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Add data to repo for easy read in\n",
    "THUMBNAIL_BASE_DIR = Path('/Users/hayleygoldblatt/Documents/cosc545/m7_p3_perfect_vine_compilation/Data/thumbs')\n",
    "INPUT_JSONL_FILE = '/Users/hayleygoldblatt/Documents/cosc545/m7_p3_perfect_vine_compilation/Data/after_last_cleaning_all_embeddings.jsonl'\n",
    "N_CLUSTERS = 5000\n",
    "RANDOM_STATE = 41\n",
    "FIG_SIZE = (12, 10)\n",
    "DOT_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211be24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/hayleygoldblatt/Documents/cosc545/m7_p3_perfect_vine_compilation/Data/after_last_cleaning_all_embeddings.jsonl...\n",
      "Successfully loaded 28385 consistent embeddings (Skipped 0 invalid/inconsistent entries).\n"
     ]
    }
   ],
   "source": [
    "df_data, embeddings_list = load_embeddings(INPUT_JSONL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ada9c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>video_id_short</th>\n",
       "      <th>whisper_transcript</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20130626125209_182352F6-CFF3-497C-9891-8FF7D18...</td>\n",
       "      <td>182352F6-C</td>\n",
       "      <td>All DOGROUND... ALL DOGROUND... Call ohmd</td>\n",
       "      <td>[-0.031610012, 0.03581158, 0.031906445, 0.0145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20130627194331_18C3F6CB-6E8C-4DD1-A245-CCA4CF2...</td>\n",
       "      <td>18C3F6CB-6</td>\n",
       "      <td>Baby, Baby!</td>\n",
       "      <td>[-0.02479268, 0.029688096, 0.028634664, 0.0226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130628013622_14CF3EAD-D4F8-4174-885A-27A2D49...</td>\n",
       "      <td>14CF3EAD-D</td>\n",
       "      <td>How are you? Great Bob! We're all in a little ...</td>\n",
       "      <td>[-0.015824113, 0.033187184, 0.01681333, 0.0065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20130628211747_18112C4B-742F-4745-ACB1-C76F89A...</td>\n",
       "      <td>18112C4B-7</td>\n",
       "      <td></td>\n",
       "      <td>[-0.024460625, 0.03128573, 0.0068606776, 0.033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20130702110757_0AC9933B-F979-4A43-BB29-89C0C05...</td>\n",
       "      <td>0AC9933B-F</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.026678782, 0.03043931, 0.0365816, 0.024619...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename video_id_short  \\\n",
       "0  20130626125209_182352F6-CFF3-497C-9891-8FF7D18...     182352F6-C   \n",
       "1  20130627194331_18C3F6CB-6E8C-4DD1-A245-CCA4CF2...     18C3F6CB-6   \n",
       "2  20130628013622_14CF3EAD-D4F8-4174-885A-27A2D49...     14CF3EAD-D   \n",
       "3  20130628211747_18112C4B-742F-4745-ACB1-C76F89A...     18112C4B-7   \n",
       "4  20130702110757_0AC9933B-F979-4A43-BB29-89C0C05...     0AC9933B-F   \n",
       "\n",
       "                                  whisper_transcript  \\\n",
       "0          All DOGROUND... ALL DOGROUND... Call ohmd   \n",
       "1                                        Baby, Baby!   \n",
       "2  How are you? Great Bob! We're all in a little ...   \n",
       "3                                                      \n",
       "4                                               None   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.031610012, 0.03581158, 0.031906445, 0.0145...  \n",
       "1  [-0.02479268, 0.029688096, 0.028634664, 0.0226...  \n",
       "2  [-0.015824113, 0.033187184, 0.01681333, 0.0065...  \n",
       "3  [-0.024460625, 0.03128573, 0.0068606776, 0.033...  \n",
       "4  [-0.026678782, 0.03043931, 0.0365816, 0.024619...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c4420",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "https://medium.com/@evgen.ryzhkov/5-stages-of-data-preprocessing-for-k-means-clustering-b755426f9932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d713451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LinearSVC from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator _SigmoidCalibration from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator CalibratedClassifierCV from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25860, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO remove vines with swears/inappropriate content\n",
    "from profanity_check import predict\n",
    "df_data['profanity_score'] = predict(df_data['whisper_transcript'].fillna(''))\n",
    "df_data = df_data[df_data['profanity_score'] == 0].reset_index(drop=True)\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2621c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO filter to niche topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b41ca0",
   "metadata": {},
   "source": [
    "## Clustering Analysis\n",
    "https://medium.com/@RobuRishabh/clustering-text-data-with-k-means-and-visualizing-with-t-sne-9bc1fe7d8fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4db16532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the 'Features' column into new columns\n",
    "expanded_features = df_data['embedding'].apply(pd.Series)\n",
    "\n",
    "# Optionally, rename the new columns for clarity\n",
    "expanded_features.columns = [f'embedding_{i+1}' for i in range(expanded_features.shape[1])]\n",
    "\n",
    "# Concatenate the expanded features with the original DataFrame (excluding the original list column)\n",
    "df_expanded = pd.concat([expanded_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cc4bc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "      <th>embedding_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031610</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>0.031906</td>\n",
       "      <td>0.014598</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>0.023161</td>\n",
       "      <td>-0.002574</td>\n",
       "      <td>-0.031405</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>-0.055055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024395</td>\n",
       "      <td>0.019522</td>\n",
       "      <td>0.049779</td>\n",
       "      <td>-0.027164</td>\n",
       "      <td>-0.020035</td>\n",
       "      <td>-0.095322</td>\n",
       "      <td>-0.004795</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>0.036391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.029688</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>-0.036946</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.050425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026428</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>-0.026537</td>\n",
       "      <td>-0.019204</td>\n",
       "      <td>-0.097297</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.031497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015824</td>\n",
       "      <td>0.033187</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>-0.023289</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>-0.022123</td>\n",
       "      <td>-0.035444</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>-0.044755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.061825</td>\n",
       "      <td>-0.018192</td>\n",
       "      <td>-0.021996</td>\n",
       "      <td>-0.082239</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>0.018713</td>\n",
       "      <td>0.033017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.024461</td>\n",
       "      <td>0.031286</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>-0.037236</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-0.025504</td>\n",
       "      <td>0.020557</td>\n",
       "      <td>-0.051506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024206</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.035380</td>\n",
       "      <td>-0.027134</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>-0.101082</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.028146</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.034151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.026679</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>0.036582</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>-0.039549</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.035731</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>-0.054270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020595</td>\n",
       "      <td>0.026193</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>-0.030858</td>\n",
       "      <td>-0.024733</td>\n",
       "      <td>-0.101732</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.031207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0    -0.031610     0.035812     0.031906     0.014598    -0.037266   \n",
       "1    -0.024793     0.029688     0.028635     0.022613    -0.040009   \n",
       "2    -0.015824     0.033187     0.016813     0.006594    -0.023289   \n",
       "3    -0.024461     0.031286     0.006861     0.033299    -0.037236   \n",
       "4    -0.026679     0.030439     0.036582     0.024620    -0.039549   \n",
       "\n",
       "   embedding_6  embedding_7  embedding_8  embedding_9  embedding_10  ...  \\\n",
       "0     0.023161    -0.002574    -0.031405     0.012062     -0.055055  ...   \n",
       "1     0.026508    -0.002295    -0.036946     0.018670     -0.050425  ...   \n",
       "2     0.032709    -0.022123    -0.035444     0.014615     -0.044755  ...   \n",
       "3     0.015712     0.001993    -0.025504     0.020557     -0.051506  ...   \n",
       "4     0.024891     0.000604    -0.035731     0.015495     -0.054270  ...   \n",
       "\n",
       "   embedding_759  embedding_760  embedding_761  embedding_762  embedding_763  \\\n",
       "0      -0.024395       0.019522       0.049779      -0.027164      -0.020035   \n",
       "1      -0.026428       0.027089       0.050627      -0.026537      -0.019204   \n",
       "2      -0.041138       0.017483       0.061825      -0.018192      -0.021996   \n",
       "3      -0.024206       0.040424       0.035380      -0.027134      -0.021946   \n",
       "4      -0.020595       0.026193       0.048427      -0.030858      -0.024733   \n",
       "\n",
       "   embedding_764  embedding_765  embedding_766  embedding_767  embedding_768  \n",
       "0      -0.095322      -0.004795       0.015109       0.012812       0.036391  \n",
       "1      -0.097297      -0.001054       0.014319       0.007215       0.031497  \n",
       "2      -0.082239      -0.009018       0.034478       0.018713       0.033017  \n",
       "3      -0.101082       0.002300       0.028146       0.000513       0.034151  \n",
       "4      -0.101732      -0.000976       0.010061       0.003600       0.031207  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f69419",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_values:\n\u001b[32m     12\u001b[39m     kmeans = KMeans(n_clusters=k, init=\u001b[33m'\u001b[39m\u001b[33mk-means++\u001b[39m\u001b[33m'\u001b[39m, max_iter=\u001b[32m300\u001b[39m, n_init=\u001b[32m10\u001b[39m, random_state=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_expanded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     wcss.append(kmeans.inertia_) \u001b[38;5;66;03m# inertia_ is the WCSS\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 3. Plot the elbow curve\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1499\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1495\u001b[39m best_inertia, best_labels = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m._n_init):\n\u001b[32m   1498\u001b[39m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1499\u001b[39m     centers_init = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitialization complete\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1014\u001b[39m, in \u001b[36m_BaseKMeans._init_centroids\u001b[39m\u001b[34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[39m\n\u001b[32m   1011\u001b[39m     sample_weight = sample_weight[init_indices]\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mk-means++\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     centers, _ = \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1022\u001b[39m     seeds = random_state.choice(\n\u001b[32m   1023\u001b[39m         n_samples,\n\u001b[32m   1024\u001b[39m         size=n_clusters,\n\u001b[32m   1025\u001b[39m         replace=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1026\u001b[39m         p=sample_weight / sample_weight.sum(),\n\u001b[32m   1027\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:251\u001b[39m, in \u001b[36m_kmeans_plusplus\u001b[39m\u001b[34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[39m\n\u001b[32m    248\u001b[39m np.clip(candidate_ids, \u001b[38;5;28;01mNone\u001b[39;00m, closest_dist_sq.size - \u001b[32m1\u001b[39m, out=candidate_ids)\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Compute distances to center candidates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m distance_to_candidates = \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    253\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[32m    256\u001b[39m np.minimum(closest_dist_sq, distance_to_candidates, out=distance_to_candidates)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:421\u001b[39m, in \u001b[36m_euclidean_distances\u001b[39m\u001b[34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[39m\n\u001b[32m    416\u001b[39m         YY = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == xp.float32 \u001b[38;5;129;01mor\u001b[39;00m Y.dtype == xp.float32:\n\u001b[32m    419\u001b[39m     \u001b[38;5;66;03m# To minimize precision issues with float32, we compute the distance\u001b[39;00m\n\u001b[32m    420\u001b[39m     \u001b[38;5;66;03m# matrix on chunks of X and Y upcast to float64\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     distances = \u001b[43m_euclidean_distances_upcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[32m    424\u001b[39m     distances = -\u001b[32m2\u001b[39m * safe_sparse_dot(X, Y.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:641\u001b[39m, in \u001b[36m_euclidean_distances_upcast\u001b[39m\u001b[34m(X, XX, Y, YY, batch_size)\u001b[39m\n\u001b[32m    638\u001b[39m     d = distances[y_slice, x_slice].T\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     Y_chunk = \u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp_max_float\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m YY \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    643\u001b[39m         YY_chunk = row_norms(Y_chunk, squared=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cosc545/lib/python3.12/site-packages/sklearn/externals/array_api_compat/numpy/_aliases.py:125\u001b[39m, in \u001b[36mastype\u001b[39m\u001b[34m(x, dtype, copy, device)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mastype\u001b[39m(\n\u001b[32m    117\u001b[39m     x: Array,\n\u001b[32m    118\u001b[39m     dtype: DType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m     device: Device | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    123\u001b[39m ) -> Array:\n\u001b[32m    124\u001b[39m     _helpers._check_device(np, device)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#TODO Test K-Means to determine number of clusters (elbow plot)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# 2. Calculate WCSS (Within-Cluster Sum of Squares) for different k values\n",
    "wcss = []\n",
    "k_values = range(1, 100)  # Test k from 1 to 10\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(df_expanded)\n",
    "    wcss.append(kmeans.inertia_) # inertia_ is the WCSS\n",
    "\n",
    "# 3. Plot the elbow curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Plot for Optimal K')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a805a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO perform K-Means with optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO compare K-Means results with DBSCAN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80dab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Visualize K-Means clusters with t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d8989",
   "metadata": {},
   "source": [
    "## Vine Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0548d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Based on clustering results, create compilations of similar vines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9850da5",
   "metadata": {},
   "source": [
    "## Compilation Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4025c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbc64e9c",
   "metadata": {},
   "source": [
    "## Reflection Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de21879",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosc545",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
